{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import NMF\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "\n",
    "# read data\n",
    "movies = pd.read_csv(\"data/ml-20m/movies.csv\")\n",
    "ratings = pd.read_csv(\"data/ml-20m/ratings.csv\")\n",
    "\n",
    "# join\n",
    "ratings_joined = pd.merge(ratings, movies)\n",
    "\n",
    "# ratingsをsparse matrixに変換して横持ちにする\n",
    "action_adventure_ratings = ratings_joined.query(\"genres.str.contains('Action') or genres.str.contains('Adventure')\", \n",
    "                                                engine='python').reset_index(drop=True)\n",
    "# indexing ids\n",
    "# userid\n",
    "userid_unique = pd.Series(action_adventure_ratings[\"userId\"].unique())\n",
    "index_userid_dict = userid_unique.to_dict()\n",
    "# inverse\n",
    "userid_index_dict = dict(map(reversed, index_userid_dict.items()))\n",
    "\n",
    "# itemid\n",
    "itemid_unique = pd.Series(action_adventure_ratings[\"movieId\"].unique())\n",
    "index_itemid_dict = itemid_unique.to_dict()\n",
    "# inverse\n",
    "itemid_index_dict = dict(map(reversed, index_itemid_dict.items()))\n",
    "\n",
    "action_adventure_ratings[\"user_id\"] = action_adventure_ratings[\"userId\"].map(userid_index_dict)\n",
    "action_adventure_ratings[\"item_id\"] = action_adventure_ratings[\"movieId\"].map(itemid_index_dict)\n",
    "\n",
    "# reindexしたidを使って、アイテムとジャンルの対応が取れるdictを作る\n",
    "itemid_genres_dict = action_adventure_ratings[['item_id', 'genres']].set_index('item_id')['genres'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudpickle\n",
    "X_train = cloudpickle.load(open(\"output/X_train.pkl\",\"rb\"))\n",
    "X_test = cloudpickle.load(open(\"output/X_test.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregateのtrainをactionとadventureに分離する\n",
    "# actionの列\n",
    "action_columns = [v for v in range(X_train.shape[1]) if 'Action' in itemid_genres_dict[v]]\n",
    "# adventureの列\n",
    "adventure_columns = [v for v in range(X_train.shape[1]) if 'Adventure' in itemid_genres_dict[v]]\n",
    "\n",
    "# 選んだカラムに応じてとってくる\n",
    "action_train = X_train[:, action_columns]\n",
    "adventure_train = X_train[:, adventure_columns]\n",
    "\n",
    "# adventureのみ、アイテムidのconcatとの対応関係が必要なので辞書として持っておく\n",
    "adventure_concat_itemid_dict = {}\n",
    "count = 0\n",
    "for v in range(X_train.shape[1]):\n",
    "    if 'Adventure' in itemid_genres_dict[v]:\n",
    "        adventure_concat_itemid_dict[v] = count\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# アイテムidのconcatとの対応関係が必要なので辞書として持っておく\n",
    "action_concat_itemid_dict = {}\n",
    "count = 0\n",
    "for v in range(X_train.shape[1]):\n",
    "    if 'Action' in itemid_genres_dict[v]:\n",
    "        action_concat_itemid_dict[v] = count\n",
    "        count += 1\n",
    "# inverse\n",
    "inverse_action_concat_itemid_dict = dict(map(reversed, action_concat_itemid_dict.items()))\n",
    "\n",
    "adventure_concat_itemid_dict = {}\n",
    "count = 0\n",
    "for v in range(X_train.shape[1]):\n",
    "    if 'Adventure' in itemid_genres_dict[v]:\n",
    "        adventure_concat_itemid_dict[v] = count\n",
    "        count += 1\n",
    "# inverse\n",
    "inverse_adventure_concat_itemid_dict = dict(map(reversed, adventure_concat_itemid_dict.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# それぞれにアクションしていないユーザを削る\n",
    "# 全ユーザと、削ったあとでの対応関係を辞書として持っておく\n",
    "action_train_selected = action_train[action_train.getnnz(1)>0]\n",
    "adventure_train_selected = adventure_train[adventure_train.getnnz(1)>0]\n",
    "\n",
    "action_train_action_users = {}\n",
    "action_users = action_train.getnnz(1)>0\n",
    "count = 0\n",
    "for i in range(action_train.shape[0]):\n",
    "    if action_users[i]:\n",
    "        action_train_action_users[i] = count\n",
    "        count += 1\n",
    "\n",
    "# inverse\n",
    "inverse_action_train_action_users = dict(map(reversed, action_train_action_users.items()))\n",
    "\n",
    "adventure_train_action_users = {}\n",
    "adventure_users = adventure_train.getnnz(1)>0\n",
    "count = 0\n",
    "for i in range(adventure_train.shape[0]):\n",
    "    if adventure_users[i]:\n",
    "        adventure_train_action_users[i] = count\n",
    "        count += 1\n",
    "\n",
    "# inverse\n",
    "inverse_adventure_train_action_users = dict(map(reversed, adventure_train_action_users.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# それぞれでNMFする\n",
    "# 今回は mediateでやったときのものを使う\n",
    "action_NMF = cloudpickle.load(open(\"output/action_NMF.pkl\",\"rb\"))\n",
    "adventure_NMF = cloudpickle.load(open(\"output/adventure_NMF.pkl\",\"rb\"))\n",
    "\n",
    "action_NMF_user_vectors = action_NMF.transform(action_train_selected)\n",
    "adventure_NMF_user_vectors = adventure_NMF.transform(adventure_train_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138389/138389 [00:02<00:00, 53156.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# actionとadventureでoverlapしているユーザで、ベクトルの対応表を作る\n",
    "overlap_action_user_vectors = []\n",
    "overlap_adventure_user_vectors = []\n",
    "count = 0\n",
    "for u in tqdm(range(X_train.shape[0])):\n",
    "    if u in action_train_action_users and u in adventure_train_action_users:\n",
    "        overlap_action_user_vectors.append(action_NMF_user_vectors[action_train_action_users[u]].tolist())\n",
    "        overlap_adventure_user_vectors.append(adventure_NMF_user_vectors[adventure_train_action_users[u]].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# AutoEncoderの学習をする\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model, load_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "def build_model(input_dim, output_dim):\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "    encoded = Dense(128, activation='relu')(inputs)\n",
    "    encoded = Dense(64, activation='relu')(encoded)\n",
    "    encoded = Dense(32, activation='relu')(encoded)\n",
    "\n",
    "    decoded = Dense(64, activation='relu')(encoded)\n",
    "    decoded = Dense(128, activation='relu')(decoded)\n",
    "    decoded = Dense(output_dim, activation='sigmoid')(decoded)\n",
    "    autoencoder = Model(inputs, decoded)\n",
    "    autoencoder.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.5/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 76821 samples, validate on 25608 samples\n",
      "Epoch 1/100\n",
      "76821/76821 [==============================] - 2s 21us/step - loss: 0.1274 - accuracy: 0.7128 - val_loss: 0.0659 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06589, saving model to output/ml-20m-model.h5\n",
      "Epoch 2/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0644 - accuracy: 0.7181 - val_loss: 0.0635 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.06589 to 0.06352, saving model to output/ml-20m-model.h5\n",
      "Epoch 3/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0622 - accuracy: 0.7181 - val_loss: 0.0615 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.06352 to 0.06147, saving model to output/ml-20m-model.h5\n",
      "Epoch 4/100\n",
      "76821/76821 [==============================] - 1s 19us/step - loss: 0.0602 - accuracy: 0.7181 - val_loss: 0.0602 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.06147 to 0.06016, saving model to output/ml-20m-model.h5\n",
      "Epoch 5/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0593 - accuracy: 0.7181 - val_loss: 0.0595 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.06016 to 0.05950, saving model to output/ml-20m-model.h5\n",
      "Epoch 6/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0587 - accuracy: 0.7181 - val_loss: 0.0590 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.05950 to 0.05904, saving model to output/ml-20m-model.h5\n",
      "Epoch 7/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0583 - accuracy: 0.7181 - val_loss: 0.0587 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.05904 to 0.05874, saving model to output/ml-20m-model.h5\n",
      "Epoch 8/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0581 - accuracy: 0.7181 - val_loss: 0.0584 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.05874 to 0.05844, saving model to output/ml-20m-model.h5\n",
      "Epoch 9/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0578 - accuracy: 0.7181 - val_loss: 0.0582 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.05844 to 0.05820, saving model to output/ml-20m-model.h5\n",
      "Epoch 10/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0576 - accuracy: 0.7181 - val_loss: 0.0580 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.05820 to 0.05803, saving model to output/ml-20m-model.h5\n",
      "Epoch 11/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0574 - accuracy: 0.7181 - val_loss: 0.0579 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.05803 to 0.05790, saving model to output/ml-20m-model.h5\n",
      "Epoch 12/100\n",
      "76821/76821 [==============================] - 2s 22us/step - loss: 0.0572 - accuracy: 0.7181 - val_loss: 0.0578 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.05790 to 0.05779, saving model to output/ml-20m-model.h5\n",
      "Epoch 13/100\n",
      "76821/76821 [==============================] - 2s 21us/step - loss: 0.0571 - accuracy: 0.7181 - val_loss: 0.0575 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.05779 to 0.05752, saving model to output/ml-20m-model.h5\n",
      "Epoch 14/100\n",
      "76821/76821 [==============================] - 2s 23us/step - loss: 0.0569 - accuracy: 0.7181 - val_loss: 0.0574 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.05752 to 0.05737, saving model to output/ml-20m-model.h5\n",
      "Epoch 15/100\n",
      "76821/76821 [==============================] - 2s 21us/step - loss: 0.0568 - accuracy: 0.7181 - val_loss: 0.0572 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.05737 to 0.05723, saving model to output/ml-20m-model.h5\n",
      "Epoch 16/100\n",
      "76821/76821 [==============================] - 2s 22us/step - loss: 0.0566 - accuracy: 0.7181 - val_loss: 0.0572 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.05723 to 0.05715, saving model to output/ml-20m-model.h5\n",
      "Epoch 17/100\n",
      "76821/76821 [==============================] - 2s 22us/step - loss: 0.0565 - accuracy: 0.7181 - val_loss: 0.0571 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.05715 to 0.05709, saving model to output/ml-20m-model.h5\n",
      "Epoch 18/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0564 - accuracy: 0.7181 - val_loss: 0.0569 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.05709 to 0.05695, saving model to output/ml-20m-model.h5\n",
      "Epoch 19/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0563 - accuracy: 0.7181 - val_loss: 0.0568 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.05695 to 0.05685, saving model to output/ml-20m-model.h5\n",
      "Epoch 20/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0562 - accuracy: 0.7181 - val_loss: 0.0568 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.05685 to 0.05679, saving model to output/ml-20m-model.h5\n",
      "Epoch 21/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0561 - accuracy: 0.7181 - val_loss: 0.0567 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.05679 to 0.05668, saving model to output/ml-20m-model.h5\n",
      "Epoch 22/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0561 - accuracy: 0.7181 - val_loss: 0.0566 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.05668 to 0.05662, saving model to output/ml-20m-model.h5\n",
      "Epoch 23/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0560 - accuracy: 0.7181 - val_loss: 0.0565 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.05662 to 0.05650, saving model to output/ml-20m-model.h5\n",
      "Epoch 24/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0559 - accuracy: 0.7181 - val_loss: 0.0564 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.05650 to 0.05645, saving model to output/ml-20m-model.h5\n",
      "Epoch 25/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0558 - accuracy: 0.7181 - val_loss: 0.0565 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.05645\n",
      "Epoch 26/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0558 - accuracy: 0.7181 - val_loss: 0.0564 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.05645 to 0.05635, saving model to output/ml-20m-model.h5\n",
      "Epoch 27/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0557 - accuracy: 0.7181 - val_loss: 0.0563 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.05635 to 0.05632, saving model to output/ml-20m-model.h5\n",
      "Epoch 28/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0557 - accuracy: 0.7181 - val_loss: 0.0562 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.05632 to 0.05621, saving model to output/ml-20m-model.h5\n",
      "Epoch 29/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0556 - accuracy: 0.7181 - val_loss: 0.0562 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.05621 to 0.05619, saving model to output/ml-20m-model.h5\n",
      "Epoch 30/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0556 - accuracy: 0.7181 - val_loss: 0.0561 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.05619 to 0.05610, saving model to output/ml-20m-model.h5\n",
      "Epoch 31/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0555 - accuracy: 0.7181 - val_loss: 0.0561 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.05610 to 0.05608, saving model to output/ml-20m-model.h5\n",
      "Epoch 32/100\n",
      "76821/76821 [==============================] - 1s 19us/step - loss: 0.0555 - accuracy: 0.7181 - val_loss: 0.0560 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.05608 to 0.05605, saving model to output/ml-20m-model.h5\n",
      "Epoch 33/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0554 - accuracy: 0.7181 - val_loss: 0.0560 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.05605 to 0.05596, saving model to output/ml-20m-model.h5\n",
      "Epoch 34/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0554 - accuracy: 0.7181 - val_loss: 0.0560 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.05596\n",
      "Epoch 35/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0553 - accuracy: 0.7181 - val_loss: 0.0559 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.05596 to 0.05589, saving model to output/ml-20m-model.h5\n",
      "Epoch 36/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0553 - accuracy: 0.7181 - val_loss: 0.0559 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.05589\n",
      "Epoch 37/100\n",
      "76821/76821 [==============================] - 1s 19us/step - loss: 0.0553 - accuracy: 0.7181 - val_loss: 0.0559 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.05589 to 0.05587, saving model to output/ml-20m-model.h5\n",
      "Epoch 38/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0552 - accuracy: 0.7181 - val_loss: 0.0558 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.05587 to 0.05582, saving model to output/ml-20m-model.h5\n",
      "Epoch 39/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0552 - accuracy: 0.7181 - val_loss: 0.0558 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.05582\n",
      "Epoch 40/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0552 - accuracy: 0.7181 - val_loss: 0.0558 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.05582 to 0.05577, saving model to output/ml-20m-model.h5\n",
      "Epoch 41/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0552 - accuracy: 0.7181 - val_loss: 0.0558 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.05577 to 0.05575, saving model to output/ml-20m-model.h5\n",
      "Epoch 42/100\n",
      "76821/76821 [==============================] - 1s 19us/step - loss: 0.0551 - accuracy: 0.7181 - val_loss: 0.0557 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.05575 to 0.05575, saving model to output/ml-20m-model.h5\n",
      "Epoch 43/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0551 - accuracy: 0.7181 - val_loss: 0.0557 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.05575 to 0.05565, saving model to output/ml-20m-model.h5\n",
      "Epoch 44/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0551 - accuracy: 0.7181 - val_loss: 0.0557 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.05565\n",
      "Epoch 45/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0551 - accuracy: 0.7181 - val_loss: 0.0557 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.05565\n",
      "Epoch 46/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0550 - accuracy: 0.7181 - val_loss: 0.0556 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.05565 to 0.05563, saving model to output/ml-20m-model.h5\n",
      "Epoch 47/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0550 - accuracy: 0.7181 - val_loss: 0.0556 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.05563 to 0.05562, saving model to output/ml-20m-model.h5\n",
      "Epoch 48/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0550 - accuracy: 0.7181 - val_loss: 0.0556 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.05562 to 0.05558, saving model to output/ml-20m-model.h5\n",
      "Epoch 49/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0550 - accuracy: 0.7181 - val_loss: 0.0556 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.05558\n",
      "Epoch 50/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0550 - accuracy: 0.7181 - val_loss: 0.0555 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.05558 to 0.05553, saving model to output/ml-20m-model.h5\n",
      "Epoch 51/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0549 - accuracy: 0.7181 - val_loss: 0.0555 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.05553\n",
      "Epoch 52/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0549 - accuracy: 0.7181 - val_loss: 0.0555 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.05553 to 0.05549, saving model to output/ml-20m-model.h5\n",
      "Epoch 53/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0549 - accuracy: 0.7181 - val_loss: 0.0555 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.05549 to 0.05548, saving model to output/ml-20m-model.h5\n",
      "Epoch 54/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0549 - accuracy: 0.7181 - val_loss: 0.0555 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.05548 to 0.05546, saving model to output/ml-20m-model.h5\n",
      "Epoch 55/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0549 - accuracy: 0.7181 - val_loss: 0.0555 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.05546\n",
      "Epoch 56/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0548 - accuracy: 0.7181 - val_loss: 0.0555 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.05546 to 0.05545, saving model to output/ml-20m-model.h5\n",
      "Epoch 57/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0548 - accuracy: 0.7181 - val_loss: 0.0554 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.05545 to 0.05542, saving model to output/ml-20m-model.h5\n",
      "Epoch 58/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0548 - accuracy: 0.7181 - val_loss: 0.0554 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.05542 to 0.05538, saving model to output/ml-20m-model.h5\n",
      "Epoch 59/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0548 - accuracy: 0.7181 - val_loss: 0.0554 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.05538 to 0.05538, saving model to output/ml-20m-model.h5\n",
      "Epoch 60/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0548 - accuracy: 0.7181 - val_loss: 0.0554 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.05538\n",
      "Epoch 61/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0548 - accuracy: 0.7181 - val_loss: 0.0554 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.05538 to 0.05537, saving model to output/ml-20m-model.h5\n",
      "Epoch 62/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0547 - accuracy: 0.7181 - val_loss: 0.0554 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.05537 to 0.05536, saving model to output/ml-20m-model.h5\n",
      "Epoch 63/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0547 - accuracy: 0.7181 - val_loss: 0.0555 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.05536\n",
      "Epoch 64/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0547 - accuracy: 0.7181 - val_loss: 0.0553 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.05536 to 0.05535, saving model to output/ml-20m-model.h5\n",
      "Epoch 65/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0547 - accuracy: 0.7181 - val_loss: 0.0553 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.05535 to 0.05530, saving model to output/ml-20m-model.h5\n",
      "Epoch 66/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0547 - accuracy: 0.7181 - val_loss: 0.0553 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.05530 to 0.05529, saving model to output/ml-20m-model.h5\n",
      "Epoch 67/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0547 - accuracy: 0.7181 - val_loss: 0.0553 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.05529 to 0.05526, saving model to output/ml-20m-model.h5\n",
      "Epoch 68/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0546 - accuracy: 0.7181 - val_loss: 0.0553 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.05526\n",
      "Epoch 69/100\n",
      "76821/76821 [==============================] - 1s 17us/step - loss: 0.0546 - accuracy: 0.7181 - val_loss: 0.0553 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.05526\n",
      "Epoch 70/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0546 - accuracy: 0.7181 - val_loss: 0.0552 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.05526 to 0.05522, saving model to output/ml-20m-model.h5\n",
      "Epoch 71/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0546 - accuracy: 0.7181 - val_loss: 0.0552 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.05522\n",
      "Epoch 72/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0546 - accuracy: 0.7181 - val_loss: 0.0552 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.05522 to 0.05521, saving model to output/ml-20m-model.h5\n",
      "Epoch 73/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0546 - accuracy: 0.7181 - val_loss: 0.0553 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.05521\n",
      "Epoch 74/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0546 - accuracy: 0.7181 - val_loss: 0.0552 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.05521 to 0.05519, saving model to output/ml-20m-model.h5\n",
      "Epoch 75/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0546 - accuracy: 0.7181 - val_loss: 0.0552 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.05519\n",
      "Epoch 76/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0546 - accuracy: 0.7181 - val_loss: 0.0552 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.05519 to 0.05519, saving model to output/ml-20m-model.h5\n",
      "Epoch 77/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0545 - accuracy: 0.7181 - val_loss: 0.0552 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.05519\n",
      "Epoch 78/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0545 - accuracy: 0.7181 - val_loss: 0.0552 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.05519 to 0.05515, saving model to output/ml-20m-model.h5\n",
      "Epoch 79/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0545 - accuracy: 0.7181 - val_loss: 0.0552 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.05515\n",
      "Epoch 80/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0545 - accuracy: 0.7181 - val_loss: 0.0551 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.05515 to 0.05514, saving model to output/ml-20m-model.h5\n",
      "Epoch 81/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0545 - accuracy: 0.7181 - val_loss: 0.0551 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.05514\n",
      "Epoch 82/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0545 - accuracy: 0.7181 - val_loss: 0.0551 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.05514 to 0.05513, saving model to output/ml-20m-model.h5\n",
      "Epoch 83/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0545 - accuracy: 0.7181 - val_loss: 0.0551 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.05513 to 0.05511, saving model to output/ml-20m-model.h5\n",
      "Epoch 84/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0545 - accuracy: 0.7181 - val_loss: 0.0551 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.05511 to 0.05510, saving model to output/ml-20m-model.h5\n",
      "Epoch 85/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0545 - accuracy: 0.7181 - val_loss: 0.0551 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.05510\n",
      "Epoch 86/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0545 - accuracy: 0.7181 - val_loss: 0.0551 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.05510 to 0.05509, saving model to output/ml-20m-model.h5\n",
      "Epoch 87/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0545 - accuracy: 0.7181 - val_loss: 0.0551 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.05509\n",
      "Epoch 88/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0544 - accuracy: 0.7181 - val_loss: 0.0551 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.05509\n",
      "Epoch 89/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0544 - accuracy: 0.7181 - val_loss: 0.0551 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.05509 to 0.05507, saving model to output/ml-20m-model.h5\n",
      "Epoch 90/100\n",
      "76821/76821 [==============================] - 1s 19us/step - loss: 0.0544 - accuracy: 0.7181 - val_loss: 0.0551 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.05507\n",
      "Epoch 91/100\n",
      "76821/76821 [==============================] - 1s 19us/step - loss: 0.0544 - accuracy: 0.7181 - val_loss: 0.0550 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.05507 to 0.05504, saving model to output/ml-20m-model.h5\n",
      "Epoch 92/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0544 - accuracy: 0.7181 - val_loss: 0.0550 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.05504\n",
      "Epoch 93/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0544 - accuracy: 0.7181 - val_loss: 0.0550 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.05504\n",
      "Epoch 94/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0544 - accuracy: 0.7181 - val_loss: 0.0551 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.05504\n",
      "Epoch 95/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0544 - accuracy: 0.7181 - val_loss: 0.0550 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.05504 to 0.05502, saving model to output/ml-20m-model.h5\n",
      "Epoch 96/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0544 - accuracy: 0.7181 - val_loss: 0.0551 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.05502\n",
      "Epoch 97/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0544 - accuracy: 0.7181 - val_loss: 0.0551 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.05502\n",
      "Epoch 98/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0544 - accuracy: 0.7181 - val_loss: 0.0550 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.05502\n",
      "Epoch 99/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0544 - accuracy: 0.7181 - val_loss: 0.0550 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.05502 to 0.05500, saving model to output/ml-20m-model.h5\n",
      "Epoch 100/100\n",
      "76821/76821 [==============================] - 1s 18us/step - loss: 0.0544 - accuracy: 0.7181 - val_loss: 0.0550 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.05500 to 0.05499, saving model to output/ml-20m-model.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f5aa305fb38>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_vector, X_test_vector, y_train_vector, y_test_vector = train_test_split(overlap_action_user_vectors, overlap_adventure_user_vectors, random_state=42)\n",
    "X_train_vector, X_val_vector, y_train_vector, y_val_vector = train_test_split(X_train_vector, y_train_vector, random_state=42)\n",
    "\n",
    "epoch_size = 100\n",
    "batch_size = 256\n",
    "mcheck = ModelCheckpoint(\n",
    "    'output/ml-20m-model.h5',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1)\n",
    "es_cb = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    mode='auto')\n",
    "model = build_model(np.array(X_train_vector).shape[1], np.array(y_train_vector).shape[1])\n",
    "model.fit(\n",
    "    np.array(X_train_vector),\n",
    "    np.array(y_train_vector),\n",
    "    batch_size=batch_size,\n",
    "    epochs=epoch_size,\n",
    "    validation_data=(\n",
    "        np.array(X_val_vector),\n",
    "        np.array(y_val_vector)),\n",
    "    callbacks=[\n",
    "        mcheck,\n",
    "        es_cb],\n",
    "    shuffle=True,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 0.019421749173835046\n"
     ]
    }
   ],
   "source": [
    "# テストデータに対するRMSE計算\n",
    "from sklearn.metrics import mean_squared_error\n",
    "best_model = load_model('output/ml-20m-model.h5')\n",
    "y_pred = best_model.predict(np.array(X_test_vector))\n",
    "rmse_ = np.sqrt(mean_squared_error(y_pred, np.array(y_test_vector)))\n",
    "print('rmse: {}'.format(rmse_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vaeとで、rmseを比較し、良い方を選ぶ\n",
    "# ref. https://keras.io/examples/variational_autoencoder/\n",
    "\n",
    "from keras.layers import Lambda, Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "\n",
    "class VAE():\n",
    "    def __init__(self, input_dim, intermediate_dim, latent_dim, original_dim):\n",
    "        self.input_dim = input_dim\n",
    "        self.original_dim = original_dim\n",
    "        self.intermediate_dim = intermediate_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.z_mean = None\n",
    "        self.z_log_var = None\n",
    "\n",
    "\n",
    "    # reparameterization trick\n",
    "    # instead of sampling from Q(z|X), sample epsilon = N(0,I)\n",
    "    # z = z_mean + sqrt(var) * epsilon\n",
    "    def sampling(self, args):\n",
    "        \"\"\"Reparameterization trick by sampling from an isotropic unit Gaussian.\n",
    "\n",
    "        # Arguments\n",
    "            args (tensor): mean and log of variance of Q(z|X)\n",
    "\n",
    "        # Returns\n",
    "            z (tensor): sampled latent vector\n",
    "        \"\"\"\n",
    "\n",
    "        z_mean, z_log_var = args\n",
    "        batch = K.shape(z_mean)[0]\n",
    "        dim = K.int_shape(z_mean)[1]\n",
    "        # by default, random_normal has mean = 0 and std = 1.0\n",
    "        epsilon = K.random_normal(shape=(batch, dim))\n",
    "        return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "    def vae_loss(self, y_true, y_pred):\n",
    "        reconstruction_loss = mse(y_true, y_pred)\n",
    "        reconstruction_loss *= self.original_dim\n",
    "        kl_loss = 1 + self.z_log_var - K.square(self.z_mean) - K.exp(self.z_log_var)\n",
    "        kl_loss = K.sum(kl_loss, axis=-1)\n",
    "        kl_loss *= -0.5\n",
    "        vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "        return vae_loss\n",
    "\n",
    "\n",
    "    def build_vae(self):\n",
    "        # VAE model = encoder + decoder\n",
    "        # build encoder model\n",
    "        inputs = Input(shape=(self.input_dim,), name='encoder_input')\n",
    "        x = Dense(128, activation='relu')(inputs)\n",
    "        x = Dense(64, activation='relu')(x)\n",
    "        x = Dense(32, activation='relu')(x)\n",
    "        self.z_mean = Dense(self.latent_dim, name='z_mean')(x)\n",
    "        self.z_log_var = Dense(self.latent_dim, name='z_log_var')(x)\n",
    "\n",
    "        # use reparameterization trick to push the sampling out as input\n",
    "        # note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "        z = Lambda(self.sampling, output_shape=(self.latent_dim,), name='z')([self.z_mean, self.z_log_var])\n",
    "\n",
    "        # instantiate encoder model\n",
    "        encoder = Model(inputs, [self.z_mean, self.z_log_var, z], name='encoder')\n",
    "\n",
    "        # build decoder model\n",
    "        latent_inputs = Input(shape=(self.latent_dim,), name='z_sampling')\n",
    "        x = Dense(32, activation='relu')(latent_inputs)\n",
    "        x = Dense(64, activation='relu')(latent_inputs)\n",
    "        x = Dense(128, activation='relu')(latent_inputs)\n",
    "        decoder_outputs = Dense(self.original_dim, activation='sigmoid')(x)\n",
    "\n",
    "        # instantiate decoder model\n",
    "        decoder = Model(latent_inputs, decoder_outputs, name='decoder')\n",
    "\n",
    "        # instantiate VAE model\n",
    "        outputs = decoder(encoder(inputs)[2])\n",
    "        vae = Model(inputs, outputs, name='vae')\n",
    "        vae.compile(optimizer='adam', loss=self.vae_loss)\n",
    "        return vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(np.array(X_train_vector).shape[1], 256, 2, np.array(y_train_vector).shape[1])\n",
    "model = vae.build_vae()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vae\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              [(None, 2), (None, 2), (N 23396     \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 100)               13284     \n",
      "=================================================================\n",
      "Total params: 36,680\n",
      "Trainable params: 36,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 76821 samples, validate on 25608 samples\n",
      "Epoch 1/100\n",
      "76821/76821 [==============================] - 2s 24us/step - loss: 3.9352 - val_loss: 0.1989\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.19888, saving model to output/ml-20m-vae.h5\n",
      "Epoch 2/100\n",
      "76821/76821 [==============================] - 1s 17us/step - loss: 0.1475 - val_loss: 0.1312\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.19888 to 0.13122, saving model to output/ml-20m-vae.h5\n",
      "Epoch 3/100\n",
      "76821/76821 [==============================] - 1s 17us/step - loss: 0.1260 - val_loss: 0.1254\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.13122 to 0.12541, saving model to output/ml-20m-vae.h5\n",
      "Epoch 4/100\n",
      "76821/76821 [==============================] - 1s 17us/step - loss: 0.1230 - val_loss: 0.1240\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.12541 to 0.12401, saving model to output/ml-20m-vae.h5\n",
      "Epoch 5/100\n",
      "76821/76821 [==============================] - 1s 17us/step - loss: 0.1218 - val_loss: 0.1235\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.12401 to 0.12353, saving model to output/ml-20m-vae.h5\n",
      "Epoch 6/100\n",
      "76821/76821 [==============================] - 1s 17us/step - loss: 0.1215 - val_loss: 0.1229\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.12353 to 0.12286, saving model to output/ml-20m-vae.h5\n",
      "Epoch 7/100\n",
      "76821/76821 [==============================] - 1s 17us/step - loss: 0.1212 - val_loss: 0.1226\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.12286 to 0.12258, saving model to output/ml-20m-vae.h5\n",
      "Epoch 8/100\n",
      "76821/76821 [==============================] - 1s 17us/step - loss: 0.1207 - val_loss: 0.1223\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.12258 to 0.12227, saving model to output/ml-20m-vae.h5\n",
      "Epoch 9/100\n",
      "76821/76821 [==============================] - 1s 17us/step - loss: 0.1204 - val_loss: 0.1219\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.12227 to 0.12194, saving model to output/ml-20m-vae.h5\n",
      "Epoch 10/100\n",
      "76821/76821 [==============================] - 1s 17us/step - loss: 0.1201 - val_loss: 0.1215\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.12194 to 0.12150, saving model to output/ml-20m-vae.h5\n",
      "Epoch 11/100\n",
      "76821/76821 [==============================] - 1s 17us/step - loss: 0.1198 - val_loss: 0.1214\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.12150 to 0.12138, saving model to output/ml-20m-vae.h5\n",
      "Epoch 12/100\n",
      "76821/76821 [==============================] - 1s 17us/step - loss: 0.1195 - val_loss: 0.1209\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.12138 to 0.12089, saving model to output/ml-20m-vae.h5\n",
      "Epoch 13/100\n",
      "76821/76821 [==============================] - 1s 17us/step - loss: 0.1192 - val_loss: 0.1207\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.12089 to 0.12072, saving model to output/ml-20m-vae.h5\n",
      "Epoch 14/100\n",
      "76821/76821 [==============================] - 1s 17us/step - loss: 0.1189 - val_loss: 0.1203\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.12072 to 0.12032, saving model to output/ml-20m-vae.h5\n",
      "Epoch 15/100\n",
      "76821/76821 [==============================] - 1s 17us/step - loss: 0.1186 - val_loss: 0.1201\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.12032 to 0.12012, saving model to output/ml-20m-vae.h5\n",
      "Epoch 16/100\n",
      "76821/76821 [==============================] - 1s 17us/step - loss: 0.1184 - val_loss: 0.1199\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.12012 to 0.11985, saving model to output/ml-20m-vae.h5\n",
      "Epoch 17/100\n",
      "76821/76821 [==============================] - 1s 17us/step - loss: 0.1182 - val_loss: 0.1197\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.11985 to 0.11967, saving model to output/ml-20m-vae.h5\n",
      "Epoch 18/100\n",
      "76821/76821 [==============================] - 1s 17us/step - loss: 0.1180 - val_loss: 0.1195\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.11967 to 0.11953, saving model to output/ml-20m-vae.h5\n",
      "Epoch 19/100\n",
      "76821/76821 [==============================] - 1s 17us/step - loss: 0.1178 - val_loss: 0.1193\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.11953 to 0.11931, saving model to output/ml-20m-vae.h5\n",
      "Epoch 20/100\n",
      "76821/76821 [==============================] - 1s 17us/step - loss: 0.1177 - val_loss: 0.1192\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.11931 to 0.11920, saving model to output/ml-20m-vae.h5\n",
      "Epoch 21/100\n",
      "76821/76821 [==============================] - 1s 17us/step - loss: 0.1176 - val_loss: 0.1191\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.11920 to 0.11911, saving model to output/ml-20m-vae.h5\n",
      "Epoch 22/100\n",
      "76821/76821 [==============================] - 1s 16us/step - loss: 0.1175 - val_loss: 0.1190\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.11911 to 0.11902, saving model to output/ml-20m-vae.h5\n",
      "Epoch 23/100\n",
      "76821/76821 [==============================] - 1s 17us/step - loss: 0.1174 - val_loss: 0.1190\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.11902 to 0.11900, saving model to output/ml-20m-vae.h5\n",
      "Epoch 24/100\n",
      "76821/76821 [==============================] - 1s 17us/step - loss: 0.1174 - val_loss: 0.1189\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.11900 to 0.11889, saving model to output/ml-20m-vae.h5\n",
      "Epoch 25/100\n",
      "76821/76821 [==============================] - 1s 17us/step - loss: 0.1173 - val_loss: 0.1189\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.11889 to 0.11889, saving model to output/ml-20m-vae.h5\n",
      "Epoch 26/100\n",
      "76821/76821 [==============================] - 1s 17us/step - loss: 0.1173 - val_loss: 0.1189\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.11889 to 0.11888, saving model to output/ml-20m-vae.h5\n",
      "Epoch 27/100\n",
      "76821/76821 [==============================] - 1s 17us/step - loss: 0.1173 - val_loss: 0.1189\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.11888 to 0.11887, saving model to output/ml-20m-vae.h5\n",
      "Epoch 28/100\n",
      "76821/76821 [==============================] - 1s 17us/step - loss: 0.1173 - val_loss: 0.1188\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.11887 to 0.11885, saving model to output/ml-20m-vae.h5\n",
      "Epoch 29/100\n",
      "76821/76821 [==============================] - 1s 17us/step - loss: 0.1172 - val_loss: 0.1188\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.11885 to 0.11883, saving model to output/ml-20m-vae.h5\n",
      "Epoch 30/100\n",
      "76821/76821 [==============================] - 1s 17us/step - loss: 0.1173 - val_loss: 0.1188\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.11883\n",
      "Epoch 31/100\n",
      "76821/76821 [==============================] - 1s 17us/step - loss: 0.1172 - val_loss: 0.1188\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.11883\n",
      "Epoch 32/100\n",
      "76821/76821 [==============================] - 1s 17us/step - loss: 0.1172 - val_loss: 0.1188\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.11883 to 0.11880, saving model to output/ml-20m-vae.h5\n",
      "Epoch 33/100\n",
      "76821/76821 [==============================] - 1s 17us/step - loss: 0.1172 - val_loss: 0.1188\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.11880\n",
      "Epoch 34/100\n",
      "76821/76821 [==============================] - 1s 17us/step - loss: 0.1172 - val_loss: 0.1188\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.11880\n",
      "Epoch 35/100\n",
      "76821/76821 [==============================] - 1s 17us/step - loss: 0.1172 - val_loss: 0.1188\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.11880\n",
      "Epoch 36/100\n",
      "76821/76821 [==============================] - 1s 17us/step - loss: 0.1172 - val_loss: 0.1188\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.11880 to 0.11879, saving model to output/ml-20m-vae.h5\n",
      "Epoch 37/100\n",
      "76821/76821 [==============================] - 1s 17us/step - loss: 0.1172 - val_loss: 0.1188\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.11879 to 0.11879, saving model to output/ml-20m-vae.h5\n",
      "Epoch 38/100\n",
      "76821/76821 [==============================] - 1s 17us/step - loss: 0.1172 - val_loss: 0.1188\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.11879\n",
      "Epoch 39/100\n",
      "76821/76821 [==============================] - 1s 17us/step - loss: 0.1172 - val_loss: 0.1188\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.11879 to 0.11877, saving model to output/ml-20m-vae.h5\n",
      "Epoch 40/100\n",
      "76821/76821 [==============================] - 2s 20us/step - loss: 0.1172 - val_loss: 0.1188\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.11877\n",
      "Epoch 41/100\n",
      "76821/76821 [==============================] - 2s 20us/step - loss: 0.1172 - val_loss: 0.1189\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.11877\n",
      "Epoch 42/100\n",
      "76821/76821 [==============================] - 1s 19us/step - loss: 0.1172 - val_loss: 0.1188\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.11877\n",
      "Epoch 43/100\n",
      "76821/76821 [==============================] - 1s 19us/step - loss: 0.1172 - val_loss: 0.1189\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.11877\n",
      "Epoch 44/100\n",
      "76821/76821 [==============================] - 1s 19us/step - loss: 0.1172 - val_loss: 0.1188\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.11877\n",
      "Epoch 45/100\n",
      "76821/76821 [==============================] - 1s 19us/step - loss: 0.1172 - val_loss: 0.1189\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.11877\n",
      "Epoch 46/100\n",
      "76821/76821 [==============================] - ETA: 0s - loss: 0.117 - 1s 19us/step - loss: 0.1172 - val_loss: 0.1189\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.11877\n",
      "Epoch 47/100\n",
      "76821/76821 [==============================] - 1s 17us/step - loss: 0.1172 - val_loss: 0.1188\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.11877\n",
      "Epoch 48/100\n",
      "76821/76821 [==============================] - 1s 17us/step - loss: 0.1172 - val_loss: 0.1189\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.11877\n",
      "Epoch 49/100\n",
      "76821/76821 [==============================] - 1s 17us/step - loss: 0.1172 - val_loss: 0.1188\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.11877\n",
      "Epoch 00049: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f5aa1e49438>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_size = 100\n",
    "batch_size = 256\n",
    "mcheck = ModelCheckpoint(\n",
    "    'output/ml-20m-vae.h5',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    verbose=1)\n",
    "es_cb = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    mode='auto')\n",
    "model.fit(\n",
    "    np.array(X_train_vector),\n",
    "    np.array(y_train_vector),\n",
    "    batch_size=batch_size,\n",
    "    epochs=epoch_size,\n",
    "    validation_data=(\n",
    "        np.array(X_val_vector),\n",
    "        np.array(y_val_vector)),\n",
    "    callbacks=[\n",
    "        mcheck,\n",
    "        es_cb],\n",
    "    shuffle=True,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 0.03430552444551072\n"
     ]
    }
   ],
   "source": [
    "# テストデータに対するRMSE計算\n",
    "from sklearn.metrics import mean_squared_error\n",
    "best_model_vae = vae.build_vae()\n",
    "best_model_vae.load_weights('output/ml-20m-vae.h5')\n",
    "y_pred = best_model_vae.predict(np.array(X_test_vector))\n",
    "rmse_ = np.sqrt(mean_squared_error(y_pred, np.array(y_test_vector)))\n",
    "print('rmse: {}'.format(rmse_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(VAEのやりかたが悪かったようなだけな気もするが)今回は素のautoencoderを採用する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138389/138389 [00:28<00:00, 4845.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# 評価対象のユーザ\n",
    "test_adventure_pos_items_dict = {}\n",
    "for i in tqdm(range(X_test.shape[0])):\n",
    "    # trainでadventureにアクションしていないユーザに\n",
    "    rated_items = X_train[i, :].indices\n",
    "    if len([v for v in rated_items if 'Adventure' in itemid_genres_dict[v]]) == 0:\n",
    "        # X_testの中でstoreしているアイテムが0以上のユーザに\n",
    "        if X_test[i, :].nnz > 0:\n",
    "            test_items = []\n",
    "            selected_user_ratings = X_test[i, :]\n",
    "            value_indices = selected_user_ratings.indices\n",
    "            sorted_indices = np.argsort(-X_test[i, :].toarray())[0]\n",
    "            # valueがあるアイテムのジャンルがadventureの場合に\n",
    "            for v in sorted_indices[:len(value_indices)]:\n",
    "                if 'Adventure' in itemid_genres_dict[v]:\n",
    "                    test_items.append(v)\n",
    "            if len(test_items) > 0:\n",
    "                test_adventure_pos_items_dict[i] = test_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adventureのitemのベクトル\n",
    "adventure_item_vectors = adventure_NMF.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_user_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 643/643 [00:01<00:00, 437.33it/s]\n"
     ]
    }
   ],
   "source": [
    "from lib.recommend_util import ndcg\n",
    "ndcgs = {\n",
    "    'ndcg5':  [],\n",
    "    'ndcg10':  [],\n",
    "    'ndcg20':  [],\n",
    "    'ndcg50':  [],\n",
    "    'ndcg100':  []\n",
    "}\n",
    "count = 0\n",
    "best_model = load_model('output/ml-20m-model.h5')\n",
    "\n",
    "for userid, pos_items in tqdm(test_adventure_pos_items_dict.items()):\n",
    "   # pos_itemsをadventure_matrixの次元に変換する\n",
    "    pos_items = np.array([adventure_concat_itemid_dict[v] for v in pos_items])\n",
    "    # useridに対応するユーザベクトル(action)を得る\n",
    "    try:\n",
    "        action_userid = action_train_action_users[userid]\n",
    "    except:\n",
    "        count += 1\n",
    "        # 推薦できないユーザの場合は無条件で0を入れる\n",
    "        ndcgs['ndcg5'].append(0)\n",
    "        ndcgs['ndcg10'].append(0)\n",
    "        ndcgs['ndcg20'].append(0)\n",
    "        ndcgs['ndcg50'].append(0)\n",
    "        ndcgs['ndcg100'].append(0)\n",
    "        continue\n",
    "        \n",
    "    action_user_vector = action_NMF_user_vectors[action_userid, :]\n",
    "    # autoencoderを使ってadventureの次元に変換する\n",
    "    adventure_user_vector_action_AE = best_model.predict(action_user_vector.reshape(1, -1))\n",
    "    # adventureのitemのベクトルと掛け合わせる\n",
    "    adv_predict = np.dot(adventure_user_vector_action_AE, adventure_item_vectors)\n",
    "    # sum_ratingsをargsort\n",
    "    sorted_indices = np.array([v for v in np.argsort(-adv_predict)])[0]\n",
    "    ndcgs['ndcg5'].append(ndcg(sorted_indices[:5], pos_items))\n",
    "    ndcgs['ndcg10'].append(ndcg(sorted_indices[:10], pos_items))\n",
    "    ndcgs['ndcg20'].append(ndcg(sorted_indices[:20], pos_items))\n",
    "    ndcgs['ndcg50'].append(ndcg(sorted_indices[:50], pos_items))\n",
    "    ndcgs['ndcg100'].append(ndcg(sorted_indices[:100], pos_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg@5: 0.041694927549288024\n",
      "ndcg@10: 0.05621393671488131\n",
      "ndcg@20: 0.06599918424990463\n",
      "ndcg@50: 0.08285782158282089\n",
      "ndcg@100: 0.09670554592765138\n"
     ]
    }
   ],
   "source": [
    "print(\"ndcg@5: {}\".format(np.mean(ndcgs['ndcg5'])))\n",
    "print(\"ndcg@10: {}\".format(np.mean(ndcgs['ndcg10'])))\n",
    "print(\"ndcg@20: {}\".format(np.mean(ndcgs['ndcg20'])))\n",
    "print(\"ndcg@50: {}\".format(np.mean(ndcgs['ndcg50'])))\n",
    "print(\"ndcg@100: {}\".format(np.mean(ndcgs['ndcg100'])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
