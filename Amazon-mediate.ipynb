{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import NMF\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "import cloudpickle\n",
    "import implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "ratings = pd.read_feather('data/amazon_review_ratings.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexing ids\n",
    "# userid\n",
    "userid_unique = pd.Series(ratings[\"userId\"].unique())\n",
    "index_userid_dict = userid_unique.to_dict()\n",
    "# inverse\n",
    "userid_index_dict = dict(map(reversed, index_userid_dict.items()))\n",
    "\n",
    "# itemid\n",
    "itemid_unique = pd.Series(ratings[\"itemId\"].unique())\n",
    "index_itemid_dict = itemid_unique.to_dict()\n",
    "# inverse\n",
    "itemid_index_dict = dict(map(reversed, index_itemid_dict.items()))\n",
    "\n",
    "ratings[\"userId_reindex\"] = ratings[\"userId\"].map(userid_index_dict)\n",
    "ratings[\"itemid_reindex\"] = ratings[\"itemId\"].map(itemid_index_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reindexしたidを使って、アイテムとジャンルの対応が取れるdictを作る\n",
    "itemid_genres_dict = ratings[['itemid_reindex', 'category']].set_index('itemid_reindex')['category'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudpickle\n",
    "X_train = cloudpickle.load(open(\"output/Amazon-X_train.pkl\",\"rb\"))\n",
    "X_test = cloudpickle.load(open(\"output/Amazon-X_test.pkl\",\"rb\"))\n",
    "test_movies_and_TVs_pos_items_dict = cloudpickle.load(open('output/test_movies_and_TVs_pos_items_dict.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregateのtrainをbookとmoviesに分離する\n",
    "# bookの列\n",
    "book_columns = [v for v in range(X_train.shape[1]) if 'book' in itemid_genres_dict[v]]\n",
    "# moviesの列\n",
    "movies_columns = [v for v in range(X_train.shape[1]) if 'movies_and_TVs' in itemid_genres_dict[v]]\n",
    "\n",
    "# 選んだカラムに応じてとってくる\n",
    "book_train = X_train[:, book_columns]\n",
    "movies_train = X_train[:, movies_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moviesのみ、アイテムidのconcatとの対応関係が必要なので辞書として持っておく\n",
    "movies_concat_itemid_dict = {}\n",
    "count = 0\n",
    "for v in range(X_train.shape[1]):\n",
    "    if 'movies_and_TVs' in itemid_genres_dict[v]:\n",
    "        movies_concat_itemid_dict[v] = count\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# それぞれにアクションしていないユーザを削る\n",
    "# 全ユーザと、削ったあとでの対応関係を辞書として持っておく\n",
    "book_train_selected = book_train[book_train.getnnz(1)>0]\n",
    "movies_train_selected = movies_train[movies_train.getnnz(1)>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_train_action_users = {}\n",
    "book_users = book_train.getnnz(1)>0\n",
    "count = 0\n",
    "for i in range(book_train.shape[0]):\n",
    "    if book_users[i]:\n",
    "        book_train_action_users[i] = count\n",
    "        count += 1\n",
    "\n",
    "# inverse\n",
    "inverse_book_train_action_users = dict(map(reversed, book_train_action_users.items()))\n",
    "\n",
    "movies_train_action_users = {}\n",
    "movies_users = movies_train.getnnz(1)>0\n",
    "count = 0\n",
    "for i in range(movies_train.shape[0]):\n",
    "    if movies_users[i]:\n",
    "        movies_train_action_users[i] = count\n",
    "        count += 1\n",
    "\n",
    "# inverse\n",
    "inverse_movies_train_action_users = dict(map(reversed, movies_train_action_users.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Intel MKL BLAS detected. Its highly recommend to set the environment variable 'export MKL_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67d5ce9a580b43649a5df0685d7ee1f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# それぞれでALSをする\n",
    "np.random.seed(42)\n",
    "book_ALS = implicit.als.AlternatingLeastSquares(factors=100)\n",
    "book_ALS.fit(book_train_selected.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f24c169e2bff4864a3d21c17e6bd9e01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "movies_ALS = implicit.als.AlternatingLeastSquares(factors=100)\n",
    "movies_ALS.fit(movies_train_selected.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "         metric_params=None, n_jobs=1, n_neighbors=5, p=2, radius=1.0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# book側のユーザについて近傍検索空間を作成\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "neigh = NearestNeighbors()\n",
    "neigh.fit(book_ALS.user_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1120/10250 [02:59<27:03,  5.62it/s]"
     ]
    }
   ],
   "source": [
    "neighbors_users = {}\n",
    "# movies側にアクションしていないユーザについて\n",
    "for userid in tqdm(test_movies_and_TVs_pos_items_dict.keys()):\n",
    "    # bookの次元におけるこのユーザのベクトルを得る\n",
    "    try:\n",
    "        book_user_id = book_train_action_users[userid]\n",
    "    except:\n",
    "        continue\n",
    "    book_user_vector = book_ALS.user_factors[book_user_id,:]\n",
    "    # 候補ユーザを得る(これら候補ユーザはbookの次元)\n",
    "    candidate_users = neigh.kneighbors([book_user_vector], 100, return_distance=False)[0][1:]\n",
    "    # concatの次元に戻す\n",
    "    candidate_users_ = [inverse_book_train_action_users[v] for v in candidate_users]\n",
    "    candidates_ = []\n",
    "    for c in candidate_users_:\n",
    "        # movies_trainに存在しているかを確認する\n",
    "        if c in movies_train_action_users:\n",
    "            # 存在しているならneighbors_usersにconcatの次元のuseridで足す\n",
    "            candidates_.append(c)\n",
    "    neighbors_users[userid] = candidates_[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10250/10250 [02:22<00:00, 71.97it/s]\n"
     ]
    }
   ],
   "source": [
    "from lib.recommend_util import ndcg\n",
    "# neighbors_usersを使って推薦する\n",
    "ndcgs = {\n",
    "    'ndcg5':  [],\n",
    "    'ndcg10':  [],\n",
    "    'ndcg20':  [],\n",
    "    'ndcg50':  [],\n",
    "    'ndcg100':  []\n",
    "}\n",
    "count = 0\n",
    "for userid, pos_items in tqdm(test_movies_and_TVs_pos_items_dict.items()):\n",
    "    # pos_itemsをmovies_matrixの次元に変換する\n",
    "    pos_items = np.array([movies_concat_itemid_dict[v] for v in pos_items])\n",
    "    if userid in neighbors_users:\n",
    "        neighs = neighbors_users[userid]\n",
    "        sum_ratings = np.zeros(movies_ALS.item_factors.shape[0])\n",
    "        for v in neighs:\n",
    "            v_movies = movies_train_action_users[v]\n",
    "            sum_ratings += np.dot(movies_ALS.user_factors[v_movies, :], movies_ALS.item_factors.T)\n",
    "        # sum_ratingsをargsort\n",
    "        sorted_indices = np.array([v for v in np.argsort(-sum_ratings)])\n",
    "        ndcgs['ndcg5'].append(ndcg(sorted_indices[:5], pos_items))\n",
    "        ndcgs['ndcg10'].append(ndcg(sorted_indices[:10], pos_items))\n",
    "        ndcgs['ndcg20'].append(ndcg(sorted_indices[:20], pos_items))\n",
    "        ndcgs['ndcg50'].append(ndcg(sorted_indices[:50], pos_items))\n",
    "        ndcgs['ndcg100'].append(ndcg(sorted_indices[:100], pos_items))\n",
    "    else:\n",
    "        count += 1\n",
    "        # 推薦できないユーザの場合は無条件で0を入れる\n",
    "        ndcgs['ndcg5'].append(0)\n",
    "        ndcgs['ndcg10'].append(0)\n",
    "        ndcgs['ndcg20'].append(0)\n",
    "        ndcgs['ndcg50'].append(0)\n",
    "        ndcgs['ndcg100'].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg@5: 0.004831150312612696\n",
      "ndcg@10: 0.006653583658177678\n",
      "ndcg@20: 0.009500250696250033\n",
      "ndcg@50: 0.014420981659326794\n",
      "ndcg@100: 0.0197377973405826\n"
     ]
    }
   ],
   "source": [
    "print(\"ndcg@5: {}\".format(np.mean(ndcgs['ndcg5'])))\n",
    "print(\"ndcg@10: {}\".format(np.mean(ndcgs['ndcg10'])))\n",
    "print(\"ndcg@20: {}\".format(np.mean(ndcgs['ndcg20'])))\n",
    "print(\"ndcg@50: {}\".format(np.mean(ndcgs['ndcg50'])))\n",
    "print(\"ndcg@100: {}\".format(np.mean(ndcgs['ndcg100'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルなどを保存\n",
    "import cloudpickle\n",
    "cloudpickle.dump(book_ALS, open(\"output/book_ALS.pkl\", \"wb\"))\n",
    "cloudpickle.dump(movies_ALS, open(\"output/movies_ALS.pkl\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
