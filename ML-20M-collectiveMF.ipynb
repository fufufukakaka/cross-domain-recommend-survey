{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import NMF\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "\n",
    "# read data\n",
    "movies = pd.read_csv(\"data/ml-20m/movies.csv\")\n",
    "ratings = pd.read_csv(\"data/ml-20m/ratings.csv\")\n",
    "\n",
    "# join\n",
    "ratings_joined = pd.merge(ratings, movies)\n",
    "\n",
    "# ratingsをsparse matrixに変換して横持ちにする\n",
    "action_adventure_ratings = ratings_joined.query(\"genres.str.contains('Action') or genres.str.contains('Adventure')\", \n",
    "                                                engine='python').reset_index(drop=True)\n",
    "# indexing ids\n",
    "# userid\n",
    "userid_unique = pd.Series(action_adventure_ratings[\"userId\"].unique())\n",
    "index_userid_dict = userid_unique.to_dict()\n",
    "# inverse\n",
    "userid_index_dict = dict(map(reversed, index_userid_dict.items()))\n",
    "\n",
    "# itemid\n",
    "itemid_unique = pd.Series(action_adventure_ratings[\"movieId\"].unique())\n",
    "index_itemid_dict = itemid_unique.to_dict()\n",
    "# inverse\n",
    "itemid_index_dict = dict(map(reversed, index_itemid_dict.items()))\n",
    "\n",
    "action_adventure_ratings[\"user_id\"] = action_adventure_ratings[\"userId\"].map(userid_index_dict)\n",
    "action_adventure_ratings[\"item_id\"] = action_adventure_ratings[\"movieId\"].map(itemid_index_dict)\n",
    "\n",
    "# reindexしたidを使って、アイテムとジャンルの対応が取れるdictを作る\n",
    "itemid_genres_dict = action_adventure_ratings[['item_id', 'genres']].set_index('item_id')['genres'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudpickle\n",
    "X_train = cloudpickle.load(open(\"output/X_train.pkl\",\"rb\"))\n",
    "X_test = cloudpickle.load(open(\"output/X_test.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregateのtrainをactionとadventureに分離する\n",
    "# actionの列\n",
    "action_columns = [v for v in range(X_train.shape[1]) if 'Action' in itemid_genres_dict[v]]\n",
    "# adventureの列\n",
    "adventure_columns = [v for v in range(X_train.shape[1]) if 'Adventure' in itemid_genres_dict[v]]\n",
    "\n",
    "# 選んだカラムに応じてとってくる\n",
    "action_train = X_train[:, action_columns]\n",
    "adventure_train = X_train[:, adventure_columns]\n",
    "\n",
    "# adventureのみ、アイテムidのconcatとの対応関係が必要なので辞書として持っておく\n",
    "adventure_concat_itemid_dict = {}\n",
    "count = 0\n",
    "for v in range(X_train.shape[1]):\n",
    "    if 'Adventure' in itemid_genres_dict[v]:\n",
    "        adventure_concat_itemid_dict[v] = count\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cmfrec\n",
      "  Using cached https://files.pythonhosted.org/packages/aa/a4/7e7f6396225ed0646a8a686273396370ca43eecec1e2fd10c43d14715646/cmfrec-0.5.2.3.tar.gz\n",
      "Requirement already satisfied: pandas>=0.21 in /usr/local/lib/python3.5/dist-packages (from cmfrec)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.5/site-packages (from cmfrec)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.5/site-packages (from cmfrec)\n",
      "Collecting tensorflow>=1.0.0 (from cmfrec)\n",
      "  Downloading https://files.pythonhosted.org/packages/7c/fb/7b2c5b3e85ad335b53ca67deb2ef4af574dc0a8759f43b7f45e15005e449/tensorflow-1.14.0-cp35-cp35m-manylinux1_x86_64.whl (109.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 109.2MB 13kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.5/dist-packages (from pandas>=0.21->cmfrec)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.5/dist-packages (from pandas>=0.21->cmfrec)\n",
      "Requirement already satisfied: mkl-fft in /usr/local/lib/python3.5/dist-packages (from numpy->cmfrec)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.5/dist-packages (from numpy->cmfrec)\n",
      "Requirement already satisfied: mkl-random in /usr/local/lib/python3.5/dist-packages (from numpy->cmfrec)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.5/dist-packages (from numpy->cmfrec)\n",
      "Requirement already satisfied: icc-rt in /usr/local/lib/python3.5/dist-packages (from numpy->cmfrec)\n",
      "Requirement already satisfied: intel-numpy in /usr/local/lib/python3.5/dist-packages (from scipy->cmfrec)\n",
      "Collecting astor>=0.6.0 (from tensorflow>=1.0.0->cmfrec)\n",
      "  Using cached https://files.pythonhosted.org/packages/d1/4f/950dfae467b384fc96bc6469de25d832534f6b4441033c39f914efd13418/astor-0.8.0-py2.py3-none-any.whl\n",
      "Collecting termcolor>=1.1.0 (from tensorflow>=1.0.0->cmfrec)\n",
      "  Using cached https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Collecting keras-applications>=1.0.6 (from tensorflow>=1.0.0->cmfrec)\n",
      "  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 10.0MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting google-pasta>=0.1.6 (from tensorflow>=1.0.0->cmfrec)\n",
      "  Downloading https://files.pythonhosted.org/packages/d0/33/376510eb8d6246f3c30545f416b2263eee461e40940c2a4413c711bdf62d/google_pasta-0.1.7-py3-none-any.whl (52kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 12.2MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.5/dist-packages (from tensorflow>=1.0.0->cmfrec)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.5/dist-packages (from tensorflow>=1.0.0->cmfrec)\n",
      "Collecting absl-py>=0.7.0 (from tensorflow>=1.0.0->cmfrec)\n",
      "  Using cached https://files.pythonhosted.org/packages/3c/0d/7cbf64cac3f93617a2b6b079c0182e4a83a3e7a8964d3b0cc3d9758ba002/absl-py-0.8.0.tar.gz\n",
      "Collecting gast>=0.2.0 (from tensorflow>=1.0.0->cmfrec)\n",
      "  Using cached https://files.pythonhosted.org/packages/1f/04/4e36c33f8eb5c5b6c622a1f4859352a6acca7ab387257d4b3c191d23ec1d/gast-0.3.2.tar.gz\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.5/dist-packages (from tensorflow>=1.0.0->cmfrec)\n",
      "Collecting tensorboard<1.15.0,>=1.14.0 (from tensorflow>=1.0.0->cmfrec)\n",
      "  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.2MB 471kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 (from tensorflow>=1.0.0->cmfrec)\n",
      "  Using cached https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl\n",
      "Collecting keras-preprocessing>=1.0.5 (from tensorflow>=1.0.0->cmfrec)\n",
      "  Using cached https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.5/dist-packages (from tensorflow>=1.0.0->cmfrec)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorflow>=1.0.0->cmfrec)\n",
      "Requirement already satisfied: tbb==2019.* in /usr/local/lib/python3.5/dist-packages (from tbb4py->numpy->cmfrec)\n",
      "Requirement already satisfied: intel-openmp in /usr/local/lib/python3.5/dist-packages (from mkl->numpy->cmfrec)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.5/dist-packages (from keras-applications>=1.0.6->tensorflow>=1.0.0->cmfrec)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.5/dist-packages (from protobuf>=3.6.1->tensorflow>=1.0.0->cmfrec)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.5/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow>=1.0.0->cmfrec)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.5/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow>=1.0.0->cmfrec)\n",
      "Building wheels for collected packages: cmfrec, termcolor, absl-py, gast\n",
      "  Running setup.py bdist_wheel for cmfrec ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyter/.cache/pip/wheels/38/25/60/7380da6f3874971edc38b1b7e11317bc40fd8e9d01028f7cee\n",
      "  Running setup.py bdist_wheel for termcolor ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyter/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "  Running setup.py bdist_wheel for absl-py ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyter/.cache/pip/wheels/9a/1e/7a/456008eb5e47fd5de792c6139df6d5b3d5f71d51c6a0b94799\n",
      "  Running setup.py bdist_wheel for gast ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyter/.cache/pip/wheels/59/38/c6/234dc39b4f6951a0768fbc02d5b7207137a5b1d9094f0d54bf\n",
      "Successfully built cmfrec termcolor absl-py gast\n",
      "Installing collected packages: astor, termcolor, keras-applications, google-pasta, absl-py, gast, tensorboard, tensorflow-estimator, keras-preprocessing, tensorflow, cmfrec\n",
      "Successfully installed absl-py-0.8.0 astor-0.8.0 cmfrec-0.5.2.3 gast-0.3.2 google-pasta-0.1.7 keras-applications-1.0.8 keras-preprocessing-1.1.0 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0 termcolor-1.1.0\n"
     ]
    }
   ],
   "source": [
    "# collective matrix factorizationのパッケージ\n",
    "!pip3 install cmfrec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# アイテムidのconcatとの対応関係が必要なので辞書として持っておく\n",
    "action_concat_itemid_dict = {}\n",
    "count = 0\n",
    "for v in range(X_train.shape[1]):\n",
    "    if 'Action' in itemid_genres_dict[v]:\n",
    "        action_concat_itemid_dict[v] = count\n",
    "        count += 1\n",
    "# inverse\n",
    "inverse_action_concat_itemid_dict = dict(map(reversed, action_concat_itemid_dict.items()))\n",
    "\n",
    "adventure_concat_itemid_dict = {}\n",
    "count = 0\n",
    "for v in range(X_train.shape[1]):\n",
    "    if 'Adventure' in itemid_genres_dict[v]:\n",
    "        adventure_concat_itemid_dict[v] = count\n",
    "        count += 1\n",
    "# inverse\n",
    "inverse_adventure_concat_itemid_dict = dict(map(reversed, adventure_concat_itemid_dict.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# それぞれにアクションしていないユーザを削る\n",
    "# 全ユーザと、削ったあとでの対応関係を辞書として持っておく\n",
    "action_train_selected = action_train[action_train.getnnz(1)>0]\n",
    "adventure_train_selected = adventure_train[adventure_train.getnnz(1)>0]\n",
    "\n",
    "action_train_action_users = {}\n",
    "action_users = action_train.getnnz(1)>0\n",
    "count = 0\n",
    "for i in range(action_train.shape[0]):\n",
    "    if action_users[i]:\n",
    "        action_train_action_users[i] = count\n",
    "        count += 1\n",
    "\n",
    "# inverse\n",
    "inverse_action_train_action_users = dict(map(reversed, action_train_action_users.items()))\n",
    "\n",
    "adventure_train_action_users = {}\n",
    "adventure_users = adventure_train.getnnz(1)>0\n",
    "count = 0\n",
    "for i in range(adventure_train.shape[0]):\n",
    "    if adventure_users[i]:\n",
    "        adventure_train_action_users[i] = count\n",
    "        count += 1\n",
    "\n",
    "# inverse\n",
    "inverse_adventure_train_action_users = dict(map(reversed, adventure_train_action_users.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actionだけでNMFをまず行う\n",
    "action_NMF = NMF(n_components=100, random_state=42)\n",
    "action_NMF_fitted = action_NMF.fit_transform(action_train_selected)\n",
    "action_NMF_components = action_NMF.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137244, 2287)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adventure_train_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# side informationとしてaction_NMFで得られたベクトルを使う\n",
    "user_attributes = pd.DataFrame(action_NMF_fitted)\n",
    "user_attributes['UserId'] = user_attributes.index\n",
    "# useridをconcatの次元に戻す\n",
    "user_attributes['UserId'] = user_attributes['UserId'].map(inverse_action_train_action_users)\n",
    "\n",
    "item_attributes = pd.DataFrame(action_NMF_components)\n",
    "item_attributes['ItemId'] = item_attributes.index\n",
    "# itemidをconcatの次元に戻す\n",
    "item_attributes['ItemId'] = item_attributes['ItemId'].map(inverse_action_concat_itemid_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138389/138389 [00:44<00:00, 3093.53it/s]\n"
     ]
    }
   ],
   "source": [
    "# X_trainから縦持ちに復元する(X_trainが既に横持ちなので)\n",
    "userid_stacked = []\n",
    "itemid_stacked = []\n",
    "ratings_stacked = []\n",
    "\n",
    "for i in tqdm(range(X_train.shape[0])):\n",
    "    ratings = X_train[i, :].data\n",
    "    item_idx = X_train[i, :].indices\n",
    "    for idx, v in enumerate(item_idx):\n",
    "        if 'Adventure' in itemid_genres_dict[v]:\n",
    "            userid_stacked.append(i)\n",
    "            itemid_stacked.append(v)\n",
    "            ratings_stacked.append(ratings[idx])\n",
    "\n",
    "adventure_ratings_stacked = pd.DataFrame()\n",
    "adventure_ratings_stacked['UserId'] = userid_stacked\n",
    "adventure_ratings_stacked['ItemId'] = itemid_stacked\n",
    "adventure_ratings_stacked['Rating'] = ratings_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>ItemId</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserId  ItemId  Rating\n",
       "0       0       0     3.5\n",
       "1       0       1     3.5\n",
       "2       0       2     3.5\n",
       "3       0       4     4.0\n",
       "4       0       9     3.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adventure_ratings_stacked.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.5/site-packages/cmfrec/__init__.py:472: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.5/site-packages/cmfrec/__init__.py:487: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.5/site-packages/cmfrec/__init__.py:522: The name tf.losses.mean_squared_error is deprecated. Please use tf.compat.v1.losses.mean_squared_error instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.5/site-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.5/site-packages/cmfrec/__init__.py:671: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.5/site-packages/cmfrec/__init__.py:672: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.5/site-packages/cmfrec/__init__.py:676: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.5/site-packages/cmfrec/__init__.py:676: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 1.449468\n",
      "  Number of iterations: 357\n",
      "  Number of functions evaluations: 371\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<cmfrec.CMF at 0x7f1f5ff20b70>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cmfrec import CMF\n",
    "\n",
    "# fitting a model and making some recommendations\n",
    "recommender = CMF(k=20, k_main=3, k_user=2, k_item=1, reg_param=1e-4)\n",
    "recommender.fit(ratings=adventure_ratings_stacked, user_info=user_attributes, item_info=item_attributes,\n",
    "                cols_bin_user=None, cols_bin_item=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138389, 4796)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138389/138389 [00:29<00:00, 4733.18it/s]\n"
     ]
    }
   ],
   "source": [
    "# 評価対象のユーザ\n",
    "test_adventure_pos_items_dict = {}\n",
    "for i in tqdm(range(X_test.shape[0])):\n",
    "    # trainでadventureにアクションしていないユーザに\n",
    "    rated_items = X_train[i, :].indices\n",
    "    if len([v for v in rated_items if 'Adventure' in itemid_genres_dict[v]]) == 0:\n",
    "        # X_testの中でstoreしているアイテムが0以上のユーザに\n",
    "        if X_test[i, :].nnz > 0:\n",
    "            test_items = []\n",
    "            selected_user_ratings = X_test[i, :]\n",
    "            value_indices = selected_user_ratings.indices\n",
    "            sorted_indices = np.argsort(-X_test[i, :].toarray())[0]\n",
    "            # valueがあるアイテムのジャンルがadventureの場合に\n",
    "            for v in sorted_indices[:len(value_indices)]:\n",
    "                if 'Adventure' in itemid_genres_dict[v]:\n",
    "                    test_items.append(v)\n",
    "            if len(test_items) > 0:\n",
    "                test_adventure_pos_items_dict[i] = test_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138079, 25)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender.A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 643/643 [00:00<00:00, 2024.43it/s]\n"
     ]
    }
   ],
   "source": [
    "from lib.recommend_util import ndcg\n",
    "ndcgs = {\n",
    "    'ndcg5':  [],\n",
    "    'ndcg10':  [],\n",
    "    'ndcg20':  [],\n",
    "    'ndcg50':  [],\n",
    "    'ndcg100':  []\n",
    "}\n",
    "count = 0\n",
    "for userid, pos_items in tqdm(test_adventure_pos_items_dict.items()):\n",
    "    pos_items = np.array(pos_items)\n",
    "    try:\n",
    "        recommended_items = np.array(recommender.topN(user=userid, n=100))\n",
    "        ndcgs['ndcg5'].append(ndcg(recommended_items[:5], pos_items))\n",
    "        ndcgs['ndcg10'].append(ndcg(recommended_items[:10], pos_items))\n",
    "        ndcgs['ndcg20'].append(ndcg(recommended_items[:20], pos_items))\n",
    "        ndcgs['ndcg50'].append(ndcg(recommended_items[:50], pos_items))\n",
    "        ndcgs['ndcg100'].append(ndcg(recommended_items[:100], pos_items))\n",
    "    except:\n",
    "        count += 1\n",
    "        # 推薦できないユーザの場合は無条件で0を入れる\n",
    "        ndcgs['ndcg5'].append(0)\n",
    "        ndcgs['ndcg10'].append(0)\n",
    "        ndcgs['ndcg20'].append(0)\n",
    "        ndcgs['ndcg50'].append(0)\n",
    "        ndcgs['ndcg100'].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg@5: 0.0210892168303856\n",
      "ndcg@10: 0.034713835358434295\n",
      "ndcg@20: 0.04102522656205653\n",
      "ndcg@50: 0.05155763746142202\n",
      "ndcg@100: 0.06786261920702773\n"
     ]
    }
   ],
   "source": [
    "print(\"ndcg@5: {}\".format(np.mean(ndcgs['ndcg5'])))\n",
    "print(\"ndcg@10: {}\".format(np.mean(ndcgs['ndcg10'])))\n",
    "print(\"ndcg@20: {}\".format(np.mean(ndcgs['ndcg20'])))\n",
    "print(\"ndcg@50: {}\".format(np.mean(ndcgs['ndcg50'])))\n",
    "print(\"ndcg@100: {}\".format(np.mean(ndcgs['ndcg100'])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
